%!TEX root = ../article.tex
% \section{Introduction}
Nowadays, the widely used location-acquisition devices lead to an explosive increase of the movement data which is recorded in the form of trajectories. 
For example, the taxis trajectory is one of the common studied movement data which is always considered as the representative of human movement trace in a city. Using the taxi dataset in Shenzhen as an example, more than 1 million trajectory data can be collected every day, which are recorded by the sampling locations.
The analysis over these databases can be applied in many fields such as traffic management~\cite{wang2014visual}, urban planning, route recommendation~\cite{zheng2011learning} and location-based services~\cite{liu2016smartadp, zheng2010collaborative}. 

\TB{Visualizing a large collection of trajectories are used frequently in map service or smart city applications.}
The most popular and conventional method is the line-based visualization~\cite{chen2015survey}: connecting the passing points of movement objects by polylines. 
To handle the big dataset, many visualization products such as Spotfire~\footnote{\url{https://www.tibco.com/products/tibco-spotfire}} and Tableau~\footnote{\url{https://www.tableau.com/}} support advanced database management systems as a ``backend'' for the efficient data processing the query. 
The current visualization tools always don't scale well for the presentation of very large trajectory dataset due to the two challenges, visual clutter and limited rendering speed, which hinders the abilities of human-users for interactively exploring the dataset and identifying the movement patterns. 
In recent years, most of the visualization research works mainly try to address the visual clutter issue by proposing new techniques such as the spatial aggregation~\cite{zeng2013visualizing, von2015mobilitygraphs}, edge bundling~\cite{zeng2019route, thony2015vector} and density map~\cite{lampe2011interactive, scheepens2011interactive}. Instead, in this paper, we focus on the challenge of inefficient rendering in the large trajectory dataset by involving data sampling techniques. 

It is time consuming to generate very simple visualization when the data size become very large. Using Porto taxi data ~\footnote{\url{http://www.geolink.pt/ecmlpkdd2015-challenge/dataset.html}} as an example, Table~\ref{table:rendering_time} demonstrates the rendering time at each dataset size. \ZW{shall also mention which rendering toolkit is used here.} It shows that normal method takes more than 14 minutes (\ZW{seconds?}) to generate the graphics for 1 million trajectories, which is far beyond the human-acceptable response time for the interactive exploration~\cite{shneiderman1984response}.
One work closely related to ours is ScalaR~\cite{battle2013dynamic}, which adds a reduction layer between visualization layer and data management layer. The reduction layer uses an uniform random sampling method to sample data once the query results are large enough, thus to reduce the amount of data to be visualized.
Further more, Park et al. propose VAS~\cite{park2016visualization} which implements new sampling techniques to guarantee the visual quality. However, these sampling techniques are designed for the simple dataset, and have been approved effective in scatter plot or map plot. However, the trajectory sampling is more challenge due to the complexity of data form(e.g. varying lengths, lack of compact representation, difficulty in measuring the similarity) that makes traditional density-biased sampling techniques inappropriate. 
A naive solution to employ sampling idea for large-scale trajectory visualization problem is randomly selecting several trajectories from the data set then visualize it by graphics device.
However, the visualization result may be not acceptable by the user because of the visual information loss in the sparse distributed regions.


\begin{table}[h!]
	\centering
	\caption{The time used to generate the visualization with different trajectory amount. \ZW{shall add a column of number of line segments or number of nodes. } }
	\begin{tabular}{m{2.5cm}|m{2.5cm}} 
		\hline
		   Data size & Time (ms) \\ 
		\hline
		100& 2\\
		\hline
		1,000& 16\\
		\hline
		10,000& 143\\
		\hline
		100,000& 1,416\\
		\hline
		1,000,000& 13,950\\
		\hline
	\end{tabular}
	\label{table:rendering_time}
\end{table}


%
%\begin{figure}[t]
%	\centering
%	\includegraphics[width=0.4\textwidth]{pictures/introduction/timesize.png}
%	\vspace{-5mm}
%	\caption{The latency time for generating line-based visualization at each datasize.}
%	\vspace{-5mm}
%	\label{fig:rendering_time}
%\end{figure}





The major challenges to design visual quality guaranteed sampling method are:
(I) how to define visual quality theoretically? (II) how to guarantee the quality of the sampling-based visualization result?
\TB{In this work, we study how to reduce the rendering time and preserve the visual quality for the large-scale trajectory visualization.}
We extend the motivation of visualization-aware sampling to trajectory dataset and propose a novel sampling strategy, \textbf{v}isualization \textbf{a}ware \textbf{t}rajectory \textbf{s}ampling(VATS), that produces high-visual-quality line-based trajectory visualization at different zooming resolutions. 
%\QM{In this paper, we first proposed the visual fidelity loss function which effectively evaluates the visual loss of the sampling method. Then we minimize the loss function by transforming this problem to an optimization problem. Several solutions for efficiently solving the optimization problem are discussed.}
We first format visual quality by defining the loss function between the visualization results of the whole dataset and sampled dataset.
With the loss function, we analyze the hardness of the problem, and devise a visual quality guaranteed sampling algorithm for it.
Figure~\ref{fig:compare} depicts an comparison among the ground truth,  uniform random sampling and our proposed method. With the same sampling set size($1\%$), the proposed method generates a higher-fidelity visualization and support the multi-resolution very well.   
At last, color encoding are applied to enhance the distribution of trajectories. 

\begin{figure}[t]
	\centering
	\includegraphics[width=0.44\textwidth]{pictures/introduction/effectiveness.pdf}
	\vspace{-3mm}
	\caption{Trajectory sampling generated by uniform random sampling(A,C) and VQGTS(B,D) at same sampling rate. In both high-level(A,B) and low level(C,D) view, our approach preserved more detail information about the trajectories especially for the sparse regions.}
	\vspace{-5mm}
	\label{fig:compare}
\end{figure}

We summarize our contribution as follows:
\setlist{nolistsep}
\begin{itemize}[noitemsep]
  \item We formulate VATS as an optimization problem.
  \item We prove VAST problem is NP-hard and offer an efficient approximation algorithms. 
  \item We conduct several experiments using real-world data to demonstrate the effectiveness of the proposed method in comparison with random uniform sampling.
\end{itemize}


The remaining parts are constructed as follows: section 2 discusses the related work. In section 3, we identify the specific problem and provide an overview of our solution. We define the problem and propose the solution in the section 4 and 5. The implementation and experiment setting are introduced in section 6. 
In section 7, we conduct case studies and user studies to evaluate our approach. Finally, we conclude this paper and propose the possible future directions in section 8.
